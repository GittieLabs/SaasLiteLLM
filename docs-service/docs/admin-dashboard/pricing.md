# Model Pricing

View and compare pricing for all available LLM models across providers in one centralized location.

## Overview

The Model Pricing page provides a comprehensive overview of pricing for 40+ models across OpenAI, Anthropic, Google Gemini, and Fireworks AI. This helps administrators make informed decisions when creating model aliases and understanding cost implications.

!!! info "New in v1.0.0"
    The Model Pricing page was introduced in version 1.0.0 to provide transparency into provider pricing and help with model selection.

## Key Features

- **Multi-Provider View** - See pricing for OpenAI, Anthropic, Gemini, and Fireworks AI in one place
- **Real-Time Pricing** - Pricing data sourced from `llm_pricing_current.json`
- **Search & Filter** - Find specific models quickly
- **Provider Comparison** - Compare costs across providers
- **Context Window Info** - View maximum context length for each model
- **Per-Million Token Pricing** - Standardized $/million tokens format
- **Example Cost Calculator** - Calculate costs for sample workloads

## Accessing Model Pricing

Navigate to **Model Pricing** from the sidebar in the Admin Dashboard.

![Model Pricing Page](../assets/screenshots/pricing.png)

## Understanding the Pricing Table

### Column Descriptions

| Column | Description |
|--------|-------------|
| **Model Name** | Display name of the model |
| **Provider** | LLM provider (OpenAI, Anthropic, Gemini, Fireworks) |
| **Model ID** | Technical identifier used in API calls |
| **Input Price** | Cost per million input tokens ($/M tokens) |
| **Output Price** | Cost per million output tokens ($/M tokens) |
| **Context Window** | Maximum tokens (input + output) supported |
| **Description** | Brief description of model capabilities |

### Pricing Format

All prices are displayed in **dollars per million tokens** ($/M tokens):

- **Input tokens**: Text sent to the model (prompts, context)
- **Output tokens**: Text generated by the model (responses)

**Example**: GPT-4o
- Input: $2.50 / M tokens
- Output: $10.00 / M tokens

For a request with 10,000 input tokens and 2,000 output tokens:
```
Input cost:  10,000 / 1,000,000 × $2.50 = $0.025
Output cost: 2,000 / 1,000,000 × $10.00 = $0.020
Total cost: $0.045
```

## Filtering and Search

### Search by Model Name

Use the search box to find specific models:
- Type model name or provider
- Results update in real-time
- Case-insensitive search

**Examples:**
- Search "gpt-5" → Shows all GPT-5 variants
- Search "claude" → Shows all Claude models
- Search "flash" → Shows Gemini Flash models

### Filter by Provider

Click provider badges to filter:
- **All Providers** - Show all models (default)
- **OpenAI** - GPT-5, GPT-4.1, GPT-4o, o3/o4-mini (10 models)
- **Anthropic** - Claude Opus, Sonnet, Haiku (8 models)
- **Gemini** - Gemini 2.5, 2.0, 1.5 variants (8 models)
- **Fireworks** - Llama, DeepSeek, Qwen, Mixtral (10 models)

## Provider Overview

### OpenAI Models

**Latest Models (2025):**
- **GPT-5** - Most capable model, 400K context ($1.25 / $10.00)
- **GPT-5 Mini** - Faster, cost-effective ($0.30 / $1.20)
- **GPT-4.1** - Enhanced GPT-4 ($2.00 / $8.00)
- **o3** - Reasoning model ($1.00 / $4.00)

**Popular Models:**
- **GPT-4o** - Multimodal flagship ($2.50 / $10.00)
- **GPT-4o Mini** - Cost-effective ($0.15 / $0.60)

### Anthropic Models

**Latest Models (2025):**
- **Claude Opus 4.1** - Most capable, 200K context ($15.00 / $75.00)
- **Claude Sonnet 4.5** - Balanced performance ($3.00 / $15.00)
- **Claude Haiku 4.5** - Fast and affordable ($0.80 / $4.00)

**Context Windows:**
- Opus 4: 200K tokens
- Sonnet 4.5: 200K tokens
- Haiku 4.5: 200K tokens

### Google Gemini Models

**Latest Models (2025):**
- **Gemini 2.5 Pro** - Most capable, 2M context ($1.25 / $5.00)
- **Gemini 2.5 Flash** - Fast, affordable ($0.075 / $0.30)
- **Gemini 2.0 Pro** - Production-ready ($1.00 / $4.00)

**Unique Features:**
- Largest context windows (up to 2M tokens)
- Most cost-effective for large contexts
- Strong multimodal capabilities

### Fireworks AI Models

**Latest Models (2025):**
- **DeepSeek R1** - Reasoning model ($0.90 / $0.90)
- **Llama 3.3 70B** - Open source flagship ($0.90 / $0.90)
- **Qwen 2.5 72B** - Multilingual ($0.90 / $0.90)
- **Mixtral 8x22B** - Mixture-of-Experts ($0.90 / $0.90)

**Benefits:**
- Consistent, competitive pricing
- Open-source models
- Vision models available

## Cost Comparison Examples

### Document Analysis (1,000 input / 500 output tokens)

| Provider | Model | Input Cost | Output Cost | Total |
|----------|-------|------------|-------------|-------|
| OpenAI | GPT-4o Mini | $0.00015 | $0.00030 | **$0.00045** |
| Anthropic | Claude Haiku 4.5 | $0.00080 | $0.00200 | **$0.00280** |
| Gemini | Gemini 2.5 Flash | $0.00008 | $0.00015 | **$0.00023** ✅ |
| Fireworks | Llama 3.3 70B | $0.00090 | $0.00045 | **$0.00135** |

**Winner**: Gemini 2.5 Flash (5x cheaper than Claude Haiku)

### Large Context Analysis (100K input / 2K output tokens)

| Provider | Model | Input Cost | Output Cost | Total |
|----------|-------|------------|-------------|-------|
| OpenAI | GPT-5 | $0.12500 | $0.02000 | **$0.14500** |
| Anthropic | Claude Sonnet 4.5 | $0.30000 | $0.03000 | **$0.33000** |
| Gemini | Gemini 2.5 Pro | $0.12500 | $0.01000 | **$0.13500** ✅ |
| Fireworks | Qwen 2.5 72B | $0.09000 | $0.00180 | **$0.09180** ✅✅ |

**Winner**: Fireworks Qwen (47% cheaper than Gemini)

### Complex Reasoning (500 input / 1,000 output tokens)

| Provider | Model | Input Cost | Output Cost | Total |
|----------|-------|------------|-------------|-------|
| OpenAI | o3 | $0.00050 | $0.00400 | **$0.00450** ✅ |
| Anthropic | Claude Opus 4.1 | $0.00750 | $0.07500 | **$0.08250** |
| Gemini | Gemini 2.5 Pro | $0.00062 | $0.00500 | **$0.00562** |
| Fireworks | DeepSeek R1 | $0.00045 | $0.00090 | **$0.00135** ✅✅ |

**Winner**: Fireworks DeepSeek R1 (70% cheaper than o3)

## Using Pricing Data for Model Aliases

When creating model aliases, use this pricing page to:

1. **Compare Costs** - Find the most cost-effective model for your use case
2. **Set Markup** - Determine appropriate markup percentages
3. **Choose Fallbacks** - Select fallback models with similar pricing
4. **Budget Planning** - Estimate costs for expected usage

**Example Workflow:**
1. View pricing for all "flash" or "mini" models
2. Compare Gemini 2.5 Flash ($0.075 input) vs GPT-4o Mini ($0.15 input)
3. Create model alias with lower-cost option as primary
4. Set 30% markup: $0.075 × 1.30 = $0.098 client price
5. Add higher-quality fallback if needed

## Pricing Data Source

All pricing data comes from `llm_pricing_current.json`, which contains:

- Current pricing from official provider documentation
- Regular updates to reflect price changes
- Per-token format (converted to per-million for display)
- Context window information
- Model descriptions

**Data Accuracy:**
- Updated monthly or when providers announce changes
- Sourced from official provider pricing pages
- Validated against actual API responses

## Example Cost Calculator

Use this calculator to estimate costs for your workflows:

**Input Parameters:**
- Average input tokens per request
- Average output tokens per request
- Expected requests per month
- Choose model from pricing table

**Example Calculation:**

```
Scenario: Customer support chatbot
- Input: 500 tokens/request
- Output: 200 tokens/request
- Volume: 10,000 requests/month
- Model: GPT-4o Mini

Input cost per request:
  500 / 1,000,000 × $0.15 = $0.000075

Output cost per request:
  200 / 1,000,000 × $0.60 = $0.000120

Total cost per request: $0.000195

Monthly cost:
  $0.000195 × 10,000 = $1.95

With 30% markup:
  Provider cost: $1.95
  Client cost: $2.54
  Profit: $0.59
```

## Updating Pricing Data

!!! warning "Admin Task"
    Pricing updates require updating the `llm_pricing_current.json` file. Contact your platform administrator to request pricing updates.

**When to Update:**
- Provider announces price changes
- New models are released
- Quarterly pricing reviews
- Before major client renewals

## Related Pages

- **[Model Aliases](model-aliases.md)** - Create model aliases using pricing data
- **[Provider Credentials](provider-credentials.md)** - Configure provider API keys
- **[Cost Transparency](cost-transparency.md)** - Track profit margins
- **[Architecture](../getting-started/architecture.md)** - Understand provider integration
