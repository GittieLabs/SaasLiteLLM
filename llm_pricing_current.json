{
  "metadata": {
    "last_updated": "2025-10-23",
    "note": "Pricing in USD per million tokens unless otherwise specified",
    "sources": [
      "https://openai.com/api/pricing/",
      "https://ai.google.dev/gemini-api/docs/pricing",
      "https://docs.claude.com/en/docs/about-claude/pricing",
      "https://fireworks.ai/pricing"
    ]
  },
  "openai": {
    "gpt-4.1": {
      "input_cost_per_token": 2e-06,
      "output_cost_per_token": 8e-06,
      "cache_read_input_token_cost": 5e-07,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_prompt_caching": true
    },
    "gpt-4.1-mini": {
      "input_cost_per_token": 4e-07,
      "output_cost_per_token": 1.6e-06,
      "cache_read_input_token_cost": 1e-07,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_prompt_caching": true
    },
    "gpt-4.1-nano": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 4e-07,
      "cache_read_input_token_cost": 2.5e-08,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_prompt_caching": true
    },
    "gpt-4o": {
      "input_cost_per_token": 2.5e-06,
      "output_cost_per_token": 1e-05,
      "cache_read_input_token_cost": 1.25e-06,
      "input_cost_per_token_batches": 1.25e-06,
      "output_cost_per_token_batches": 5e-06,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_pdf_input": true
    },
    "gpt-4o-mini": {
      "input_cost_per_token": 1.5e-07,
      "output_cost_per_token": 6e-07,
      "cache_read_input_token_cost": 7.5e-08,
      "input_cost_per_token_batches": 7.5e-08,
      "output_cost_per_token_batches": 3e-07,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_pdf_input": true
    },
    "gpt-5": {
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "cache_read_input_token_cost": 1.25e-07,
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true
    },
    "gpt-5-mini": {
      "input_cost_per_token": 2.5e-07,
      "output_cost_per_token": 2e-06,
      "cache_read_input_token_cost": 2.5e-08,
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true
    },
    "gpt-5-nano": {
      "input_cost_per_token": 5e-08,
      "output_cost_per_token": 4e-07,
      "cache_read_input_token_cost": 5e-09,
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true
    },
    "o3": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 4e-06,
      "output_cost_per_reasoning_token": 4e-06,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_reasoning": true,
      "supports_vision": true
    },
    "o4-mini": {
      "input_cost_per_token": 3e-07,
      "output_cost_per_token": 1.2e-06,
      "output_cost_per_reasoning_token": 1.2e-06,
      "max_input_tokens": 200000,
      "max_output_tokens": 65536,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_reasoning": true
    }
  },
  "google": {
    "gemini-2.5-pro": {
      "input_cost_per_token": 1.25e-06,
      "input_cost_per_token_above_200k_tokens": 2.5e-06,
      "output_cost_per_token": 5e-06,
      "output_cost_per_token_above_200k_tokens": 1e-05,
      "max_input_tokens": 2097152,
      "max_output_tokens": 8192,
      "litellm_provider": "gemini",
      "mode": "chat",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_audio_input": true
    },
    "gemini-2.5-flash": {
      "input_cost_per_token": 7.5e-08,
      "output_cost_per_token": 3e-07,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "litellm_provider": "gemini",
      "mode": "chat",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_audio_input": true
    },
    "gemini-2.5-flash-lite": {
      "input_cost_per_token": 2e-08,
      "output_cost_per_token": 8e-08,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "litellm_provider": "gemini",
      "mode": "chat",
      "supports_vision": true,
      "supports_function_calling": true
    },
    "gemini-2.0-flash": {
      "input_cost_per_token": 1e-07,
      "output_cost_per_token": 4e-07,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "litellm_provider": "gemini",
      "mode": "chat",
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_audio_input": true
    },
    "gemini-2.0-flash-lite": {
      "input_cost_per_token": 4e-08,
      "output_cost_per_token": 1.6e-07,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "litellm_provider": "gemini",
      "mode": "chat",
      "supports_vision": true,
      "supports_function_calling": true
    },
    "gemini-2.0-pro": {
      "input_cost_per_token": 2.5e-06,
      "output_cost_per_token": 1e-05,
      "max_input_tokens": 2097152,
      "max_output_tokens": 8192,
      "litellm_provider": "gemini",
      "mode": "chat",
      "supports_vision": true,
      "supports_function_calling": true,
      "note": "Experimental model"
    },
    "gemini-1.5-pro": {
      "input_cost_per_token": 1.25e-06,
      "input_cost_per_token_above_128k_tokens": 2.5e-06,
      "output_cost_per_token": 5e-06,
      "output_cost_per_token_above_128k_tokens": 1e-05,
      "max_input_tokens": 2097152,
      "max_output_tokens": 8192,
      "litellm_provider": "gemini",
      "mode": "chat",
      "supports_vision": true,
      "supports_function_calling": true
    },
    "gemini-1.5-flash": {
      "input_cost_per_token": 7.5e-08,
      "input_cost_per_token_above_128k_tokens": 1.5e-07,
      "output_cost_per_token": 3e-07,
      "output_cost_per_token_above_128k_tokens": 6e-07,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "litellm_provider": "gemini",
      "mode": "chat",
      "supports_vision": true,
      "supports_function_calling": true
    }
  },
  "anthropic": {
    "claude-haiku-4-5": {
      "input_cost_per_token": 1e-06,
      "output_cost_per_token": 5e-06,
      "cache_creation_input_token_cost": 1.25e-06,
      "cache_read_input_token_cost": 1e-07,
      "max_input_tokens": 200000,
      "max_output_tokens": 16384,
      "litellm_provider": "anthropic",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_computer_use": true
    },
    "claude-haiku-3-5": {
      "input_cost_per_token": 8e-07,
      "output_cost_per_token": 4e-06,
      "cache_creation_input_token_cost": 1e-06,
      "cache_read_input_token_cost": 8e-08,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "litellm_provider": "anthropic",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true
    },
    "claude-haiku-3": {
      "input_cost_per_token": 2.5e-07,
      "output_cost_per_token": 1.25e-06,
      "cache_creation_input_token_cost": 3e-07,
      "cache_read_input_token_cost": 3e-08,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "litellm_provider": "anthropic",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true
    },
    "claude-sonnet-4-5": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "cache_creation_input_token_cost": 3.75e-06,
      "cache_read_input_token_cost": 3e-07,
      "max_input_tokens": 200000,
      "max_output_tokens": 16384,
      "litellm_provider": "anthropic",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_computer_use": true,
      "supports_pdf_input": true
    },
    "claude-sonnet-4": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "cache_creation_input_token_cost": 3.75e-06,
      "cache_read_input_token_cost": 3e-07,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "litellm_provider": "anthropic",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true
    },
    "claude-sonnet-3-7": {
      "input_cost_per_token": 3e-06,
      "output_cost_per_token": 1.5e-05,
      "cache_creation_input_token_cost": 3.75e-06,
      "cache_read_input_token_cost": 3e-07,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "litellm_provider": "anthropic",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true
    },
    "claude-opus-4-1": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 7.5e-05,
      "cache_creation_input_token_cost": 1.875e-05,
      "cache_read_input_token_cost": 1.5e-06,
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "litellm_provider": "anthropic",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_computer_use": true
    },
    "claude-opus-4": {
      "input_cost_per_token": 1.5e-05,
      "output_cost_per_token": 7.5e-05,
      "cache_creation_input_token_cost": 1.875e-05,
      "cache_read_input_token_cost": 1.5e-06,
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "litellm_provider": "anthropic",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true
    }
  },
  "fireworks": {
    "llama-v3p3-70b-instruct": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "litellm_provider": "fireworks_ai",
      "mode": "chat",
      "parameter_count": "70B",
      "supports_function_calling": true
    },
    "llama-v3p1-405b-instruct": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "litellm_provider": "fireworks_ai",
      "mode": "chat",
      "parameter_count": "405B",
      "supports_function_calling": true
    },
    "llama-v3p1-70b-instruct": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "litellm_provider": "fireworks_ai",
      "mode": "chat",
      "parameter_count": "70B",
      "supports_function_calling": true
    },
    "llama-v3p1-8b-instruct": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "litellm_provider": "fireworks_ai",
      "mode": "chat",
      "parameter_count": "8B",
      "supports_function_calling": true
    },
    "mixtral-8x7b-instruct": {
      "input_cost_per_token": 5e-07,
      "output_cost_per_token": 5e-07,
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "litellm_provider": "fireworks_ai",
      "mode": "chat",
      "parameter_count": "MoE-56B",
      "supports_function_calling": true
    },
    "mixtral-8x22b-instruct": {
      "input_cost_per_token": 1.2e-06,
      "output_cost_per_token": 1.2e-06,
      "max_input_tokens": 65536,
      "max_output_tokens": 8192,
      "litellm_provider": "fireworks_ai",
      "mode": "chat",
      "parameter_count": "MoE-176B",
      "supports_function_calling": true
    },
    "deepseek-r1": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "max_input_tokens": 64000,
      "max_output_tokens": 8192,
      "litellm_provider": "fireworks_ai",
      "mode": "chat",
      "parameter_count": ">16B",
      "supports_reasoning": true
    },
    "qwen2p5-72b-instruct": {
      "input_cost_per_token": 9e-07,
      "output_cost_per_token": 9e-07,
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "litellm_provider": "fireworks_ai",
      "mode": "chat",
      "parameter_count": "72B",
      "supports_function_calling": true
    },
    "phi-3-vision-128k-instruct": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "litellm_provider": "fireworks_ai",
      "mode": "chat",
      "parameter_count": "4.2B",
      "supports_vision": true
    },
    "firellava-13b": {
      "input_cost_per_token": 2e-07,
      "output_cost_per_token": 2e-07,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "litellm_provider": "fireworks_ai",
      "mode": "chat",
      "parameter_count": "13B",
      "supports_vision": true
    }
  },
  "pricing_notes": {
    "openai": {
      "batch_api_discount": "50% discount on input and output tokens",
      "prompt_caching": "Cache reads cost 50% less than input tokens",
      "note": "Prices shown are for standard tier. Enterprise pricing available with volume discounts."
    },
    "google": {
      "long_context_pricing": "Context >128K or >200K tokens charged at premium rates depending on model",
      "grounding": "Google Search grounding costs $35 per 1000 prompts after free daily allowance",
      "note": "Free tier available for testing. Paid tier has higher rate limits."
    },
    "anthropic": {
      "batch_api_discount": "50% discount on both input and output tokens",
      "prompt_caching": "Cache writes 1.25x base price, cache reads 0.1x base price (5-min TTL)",
      "extended_thinking": "Thinking/reasoning tokens billed as output tokens",
      "note": "Prompt caching can reduce costs by up to 90% for repeated contexts"
    },
    "fireworks": {
      "batch_discount": "50% discount on serverless pricing for batch inference",
      "fine_tuning": "No additional cost to serve fine-tuned models beyond base pricing",
      "parameter_based_pricing": "<4B: $0.10, 4-16B: $0.20, >16B: $0.90, MoE varies per 1M tokens",
      "note": "On-demand GPU deployments available with per-second billing. New users get $1 free credit."
    }
  }
}
